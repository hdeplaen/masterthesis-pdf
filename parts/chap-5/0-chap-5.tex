\chapter{Conclusion and future works}
Privacy-friendly machine learning algorithms for intrusion detection systems are appealing for network defense and more generally to the protection of private information.

Secure linear support vector machines offer solutions at a very low cost and good accuracy ($\sim 95\%$), where nearest neighbors algorithm offer a higher accuracy ($\sim 98\%$), but at high cost. The use of condensed nearest neighbors allows to drastically diminish that cost to make the algorithm practically usable. As for now, non-linear support vector machines didn't prove to be competitive against nearest neighbors methods using MPC.

Various feature reduction methods can be used to reduce the evaluation costs even more, such as PCA or $\chi^2$. When algorithms are fast, $\chi^2$ is to be preferred as it requires no pre-process. However, when the algorithms are slower and the pre-process is proportionally less expensive, PCA reduction is to be preferred as it reduces the feature vector into less dimensions for the same accuracy.

This research raises several questions for further work. One of them is whether the proposed algorithm can be improved to make them even faster. For example, it could be possible to increase the rapidity of the RBFSVM multi-class models by avoiding computing the kernel function with the same support vectors appearing multiple times (in the different SVMs of the multi-class model). However, we could predict that this is would not lead to a significant gain as the support vectors are by essence of a support vector machine, the samples near the decision boundaries. Though, these decision boundaries should be different for each class. Hence, few redundancy is expected.

Another improvement could be using more efficient algorithms, e.g. for the minimum selection phase of the nearest neighbors. The quickselect algorithm has been proposed, but presents a lot of concerns about index leakage and thus a breach in the privacy. However, solutions exist to exchange two indices of an array in a secret manner~\cite{Aly2014SecurelyProblems}.

In addition to algorithmic improvements, other dimensionality reduction algorithms exist that could maybe lead to further gain in execution cost, e.g. non-negative matrix factorization, kernel principal component analysis, linear discriminant analysis or canonical correlation analysis. Most of them have never been implemented in the (non-secure) case of intrusion detection systems. Kernel principal component analysis (KPCA) are an exception as they have been tested and deliver good results~\cite{Elkhadir2016IntrusionMethods}. Unfortunately, they are evaluated in a very similar manner to RBFSVMs and thus we expect to encounter the same problem: the high cost of computing the kernel matrix.

Further work could also include the investigation of training models directly using MPC instead of using models separately trained. This could allow different data-base owners to aggregate their data in a secret manner and to train a model on it. This way, we should be able to gain much more of the performances of distributed intrusion detection systems. A first step is the use ensemble classifiers where each model is trained on its own and the results are then aggregated using a (weighted) majority vote. This just requires to train the weights of the majority vote in a secret manner. Furthermore, it should allow the models to be more resistant against attacks that try to exploit the output of the model against specific queries trying to reconstruct some information about the data-base. Ensemble models would dilute the information obtained between different models.

