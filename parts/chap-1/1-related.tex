\section{Related works}
% IDS IN GENERAL
Intrusion detection systems are network security technique that aim to detect malicious activity comparing it to an existing database based on previous malicious activities \cite{Amudhavel2016AReview}. The general philosophy is that the an intruder has a different behaviour than a legitimate user. It can be based on two methods \cite{Winter2018}. Rule-based, which is also known as \emph{signature-based}, aims to compare a new query to a database of specific patterns --- the so-called signatures --- that contain the sole reduced information to detect an anomaly. The big advantage of these methods is that they are very leightweight and can easily detect attacks that correspond to these signatures. Their disadvantage however is their very strong dependence on these signatures and the ability to detect anomalies that are not contained in the signatures. These signatures are furthermore often specific to certain systems or architectures \cite{Ilgun1995StateApproach}. In other words, signature specific methods almost always detect the same anomalies it has in its signature database but fails at detecting anything that diverges from it \cite{Liao2013IntrusionReview}. This problem is solved by an alternative to signature-based methods: \emph{anomaly-based methods}. They rely on more abstract, statistical models that are able to generalize the attack patterns and by this mean detect attacks that have not been previously identified \cite{Dali2015ASystem}. However, the generalization property is also its drawback as they tend to also over-identify normal activities as anomalies, resulting in a high false positive rate and a low false negative rate \cite{Mukherjee1994NetworkDetection}. A lot of research has been conducted on these issues these last 20 years leading to very effective anomaly-based systems, by replacing more simple statistical models by more complex machine-learning algorithms \cite{Tsai2010ADetection}. The use of intrusion detection system is more and more critical in our connected world and is now widely used in the industry \cite{Bhatt2014TheSystems} due to the potential high financial cost of failing to detect anomalies \cite{Rossi2009UnderstandingSignaling}. Although signature-based systems are still used by some majors, the anomaly-based systems are now consisting of the wide majority \cite{Rubio2017AnalysisEcosystems}.

% DISTRIBUTED
A big improvement these last years is the use of distributed intrusion detection systems to monitor data across multiple nodes. \cite{Yegneswaran2004GlobalSystem} have built an overlay system which shows to be able to detect attacks that could not be detected on isolated nodes and furthermore increase the general detection speed. The general philosophy behind distributed intrusion detection systems is that users are not fixed, they change their ID and their target \cite{Snapp1991DIDSPrototype}. In a certain way, distributed intrusion detection systems gain more efficiently through the correlation of different individual databases \cite{RoyceRobbins2004DistributedReview}. The main problem when working with different databases is the privacy of the data. Information about the network use of a user cannot be made publicly available, nor in the distributed intrusion detection system itself, especially when it is distributed among different and independent networks. The processing of these databases through the system's algorithms have to be made privacy-friendly.

% PRIVACY-FRIENDLY
There are different approaches to privacy-preservinf data-mining \cite{Narwaria2016PrivacyArt}. The first one is based on differential privacy \cite{Dwork2008DifferentialResults} where the results are still treated in clear but anonymized in a stastical manner to limit a maximum the possibility of de-anonmyzing the data-point. This approach has been applied various machine learning algorithms such as support vector machines \cite{Zhan2005Privacy-preservingLearning} or image processing \cite{Qin2018Privacy-PreservingCloud}.

The other approach is to use cryptographically secure algorithms where the data is cryptographically hidden and processed in its hidden form to be finally revealed the the original data-owner. The big advantage of this method is there is no possible way of finding statistical information about the data processed, which is not the case of differential privacy. However, these advantages have a cost: computationally very expensive algorithms. This is called homomorphic encryption. An alternative is to use \emph{multi-party computation} where the data is distributed between different players which then process the information in such a way that the information cannot be revealed if sufficient participants are staying honest. These methods are based on theories developed in \cite{Yao1986HowSecrets}, \cite{Rabin1981HowTransfer.} and \cite{Shamir1979HowSecret}.

Multiple algorithms have been implemented on these methods for aggregation and statistical analysis of network events such as \cite{Burkhart2010SEPIA:Statistics}. However, it has the drawback of being limited to two parties and sole simple operations of aggregation and basic statistical measures. \cite{Bogdanov2018Rmind:Analysis} are proposing a similar cryptographically secure toolboxes of algorithms, this time with more than one party, but also very limited to simple statistical algorithms, e.g. linear regression. More complex machine-learning algorithms are still timid. Cryptographically private support vector machines have been theorized in \cite{Laur2006CryptographicallyMachines} but the only real implementations known to the author are given in the domain of image-processing using linear kernels \cite{Makri2017PICS:SVM}. \cite{Barnett2017ImageData} are using polynomial kernels, but using homomorphic encryption and not multi-party computation and still in the domain of image classification. There are also some implementations using neural networks, always residing on homomorphic encryption \cite{Dowlin2016CryptoNets:Research}. To the knowledge of the author, no privacy-friendly machine-learning algorithms for intrusion detection systems have been implemented using multi-party computation and not much has been done in privacy-friendly machine-learning algorithms over MPC in general.

In general, intrusion detection systems are considered to be classification problems. However, the classifiers cannot use the rough data as such. Before being used in a machine-learning, the packets --- which are of huge size --- have to be reduced to a set of features \cite{Winter2018} which is usually quite big independently of the method chosen to generate them \cite{Sekar2002Specification-basedDetection,Cho2003EfficientModel} \cite{NewsomePolygraph:Worms}. A lot of different machine-learning algorithms have been tested and used on intrusion detectino systems \cite{Tsai2009IntrusionReview}. The first one are neural networks which tend to be very effective for binary classification but less at multi-class \cite{Mukkamala2002IntrusionMachines,Akashdeep2017AClassifier,Farnaaz2016RandomSystem}. A second type of algorithms are decision trees \cite{Meeragandhi2010EffectiveRules,Papamartzivanos2018Dendron:Systems} and more generally random based forests \cite{Soheily-Khah2018IntrusionDataset}. However, decision trees and random forests are rule-based methods which are much more difficult to hide and to make privacy-friendly. Multi-party computation is difficultly compatible with rule-based methods. Fuzzy logic \cite{Shanmugavadivu2011NetworkLogic,Rout2015ADetection} is also used but much less common. Another technique is naive Bayes \cite{Chebrolu2005FeatureSystems}, but tends to have a less good accuracy, and hidden Markov models \cite{Chen2016AnomalyModel,Tsai2007DetectingModels} that suffer from the same problem. The last two and most used methods are support vector machines and nearest neighbours methods. A lot of less classical methods have also been used, but less research has been focused on them \cite{Sabhnani2003ApplicationContext}.

\cite{Mukkamala2002IntrusionMachines} have successfully used support vector machines to make the distinction between normal and attack classes using a simple SVM with gaussian kernel. Much more complex models have also been used combining KPCA and SVM and training the parameters with genetic algorithms \cite{Kuang2014ADetection}. \cite{MingTian2004UsingAttacks} have showed that adding data-points to the data-set based on statistical data of that same data-same allows to discover more complicated attacks with support vector machines. This same phenomenon has been showed, but using random forests \cite{Akashdeep2017AClassifier}. \cite{Khan2007AClustering} and \cite{Al-Yaseen2017Multi-levelSystem} have also investigated how to reduce the training set size of SVMs for intrusion detection systems training. In general SVMs are able to detect almost all kinds of problems if the model it is used in is well built. This shows the importance of the research around support vector machines for intrusion detection systems. 

Due to the cost of multi-party computation, the data-set sizes used during the hidden part of the algorithm have to be reduced a maximum without loosing in accuracy. The feature-size reduction has been implemented using principal component analysis by \cite{Eid2010PrincipleSystem,Ikram2016ImprovingSVM} and by \cite{SumaiyaThaseen2017IntrusionSVM} using $\chi^2$ feature selection (\cite{Yang:1997:CSF:645526.657137}). In general, it seems that SVM are almost always using gaussian kernel functions, sometimes polynomial, but never linear.

The nearest neighbours algorithm has also been studied for feature reduction with PCA and KPCA by \cite{Elkhadir2016IntrusionMethods}. However, algorithms for reducing the data-points number like the one proposed in \cite{Angiulli2005FastRule} seem to never have been tested.







