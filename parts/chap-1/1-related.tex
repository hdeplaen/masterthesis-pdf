\section{Related works}
% IDS IN GENERAL
Intrusion detection systems are network security techniques that aim to detect malicious activity by comparing it to an existing data-base based on previous malicious activities \cite{Amudhavel2016AReview}. The general philosophy is that an intruder has different behaviour than a legitimate user. It can be based on two methods \cite{Winter2018}. Rule-based, which is also known as \emph{signature-based}, aims to compare a new query to a data-base of specific patterns --- the so-called signatures --- that contain the sole reduced information to detect an anomaly. The big advantage of these methods is that they are very lightweight and can easily detect attacks that correspond to these signatures. Their disadvantage however is their very strong dependence on these signatures and the inability to detect anomalies that are not contained in the signatures. These signatures are furthermore often specific to certain systems or architectures \cite{Ilgun1995StateApproach}. In other words, signature specific methods almost always detect the same anomalies as the ones it has in its signature data-base, but fails at detecting anything that diverges from it \cite{Liao2013IntrusionReview}. This problem is solved by an alternative to signature-based methods: \emph{anomaly-based methods}. They rely on more abstract, statistical models that are able to generalize the attack patterns and by this way detect attacks that have not been previously identified \cite{Dali2015ASystem}. However, the generalization property has also its drawback as they tend to also over-identify normal activities as anomalies, resulting in a high false positive rate and a low false negative rate \cite{Mukherjee1994NetworkDetection}. A lot of research has been conducted on these issues in the last 20 years, leading to very effective anomaly-based systems, by replacing more simple statistical models by more complex machine-learning algorithms \cite{Tsai2010ADetection}. The use of intrusion detection system is more and more critical in our connected world and is now widely used in the industry due to the potential high financial cost of failing to detect anomalies \cite{Bhatt2014TheSystems,Rossi2009UnderstandingSignaling}. Although signature-based systems are still used by some industry majors such as Cisco Systems, the wide majority is now consisted of anomaly-based models \cite{Rubio2017AnalysisEcosystems}.

% DISTRIBUTED
A big improvement in the last years is the use of distributed intrusion detection systems to monitor data across multiple nodes. Yegneswaran et al. have built the DOMINO overlay system, which proves to be able to detect attacks that could not be detected on isolated nodes and furthermore increases the general detection speed \cite{Yegneswaran2004GlobalSystem}. The general philosophy behind distributed intrusion detection systems is that users are not fixed, they change their ID and their target \cite{Snapp1991DIDSPrototype}. In a certain way, distributed intrusion detection systems gain more efficiency through the correlation of different individual data-bases \cite{RoyceRobbins2004DistributedReview}. The main problem when working with different data-bases is the privacy of the data. Information about the network use of a user cannot be made available to the public, nor in the distributed intrusion detection system itself, especially when it is distributed among different and independent networks. The processing of these data-bases through the system's algorithms has to be made privacy-friendly.

% PRIVACY-FRIENDLY
There are different approaches to privacy-preserving data-mining \cite{Narwaria2016PrivacyArt}. The first one is based on differential privacy, where the results are still treated in clear but in anonymized statistical manner to limit a maximum the possibility of de-anonmyzing the data-points \cite{Dwork2008DifferentialResults}. This approach has been applied to various machine learning algorithms such as support vector machines or image processing \cite{Qin2018Privacy-PreservingCloud,Zhan2005Privacy-preservingLearning}.

The other approach is to use cryptographically secure algorithms where the data is cryptographically hidden and processed in its hidden form to be finally revealed to the original data-owner. The big advantage of this method is that there is no possible way of finding statistical information about the data processed, which is not the case of differential privacy. However, these advantages have a cost: they are computationally very expensive algorithms. This is called homomorphic encryption. An alternative is to use \emph{multi-party computation} where the data is distributed between different players which then process the information in such a way that the information cannot be revealed if sufficient participants are staying honest. These methods are based on ideas developed by Yao and Rabin or secret sharing \cite{Yao1986HowSecrets}, \cite{Rabin1981HowTransfer.} and \cite{Shamir1979HowSecret}.

Multiple algorithms have been implemented using multi-party computation for aggregation and statistical analysis of network events such as SEPIA \cite{Burkhart2010SEPIA:Statistics}. However, it has the drawback of being limited to two parties and only simple aggregation operations and basic statistical measures. Bogdanov et al. are proposing Rmind, a set of similar cryptographically secure toolboxes, this time with more than one party, but also limited to simple statistical algorithms, e.g. linear regression \cite{Bogdanov2018Rmind:Analysis}. More complex machine-learning algorithms are still timid. 

Cryptographically private support vector machines have been theorized by Laur et al. \cite{Laur2006CryptographicallyMachines}, but the only real implementations known to us are given in the domain of image-processing using linear kernels \cite{Makri2017PICS:SVM}. Barnett et al. are using polynomial kernels, but using homomorphic encryption and not multi-party computation, still in the domain of image classification~\cite{Barnett2017ImageData}. There are also some implementations using neural networks, always residing on homomorphic encryption \cite{Dowlin2016CryptoNets:Research}. 

Shaneck et al. have been the first to propose privacy-friendly nearest neighbors using multi-party computation, but with a clear query point \cite{Shaneck2009PrivacySearch}. Methods encrypting both the query and the data-base have been implemented using homomorphic encryption \cite{Wong2009SecureDatabases,Hu2011ProcessingHomomorphism}, but appear not to be secure over plaintext attack \cite{Yao2013SecureRevisited}. Qi et al. have proposed a specific two-party protocol based on additive secret sharing, without any implementation~\cite{QiEfficient}.

To our knowledge, no privacy-friendly machine-learning algorithms for intrusion detection systems have been implemented using multi-party computation and not much has been done in privacy-friendly machine-learning algorithms using MPC in general.

In general, intrusion detection systems are considered to be classification problems. However, the classifiers cannot use the raw data as such. Before being used in a machine-learning, the packets --- which are of huge size --- have to be reduced to a set of features \cite{Winter2018} which is usually quite big independently of the method chosen to generate them \cite{Sekar2002Specification-basedDetection,Cho2003EfficientModel} \cite{NewsomePolygraph:Worms}. A lot of different machine-learning algorithms have been tested and used on intrusion detecting systems \cite{Tsai2009IntrusionReview}. The first ones are neural networks which tend to be very effective for binary classification but less at multi-class \cite{Mukkamala2002IntrusionMachines,Akashdeep2017AClassifier,Farnaaz2016RandomSystem}. A second type of algorithms are decision trees \cite{Meeragandhi2010EffectiveRules,Papamartzivanos2018Dendron:Systems} and more generally random forest classifiers \cite{Soheily-Khah2018IntrusionDataset}. However, decision trees and random forests are rule-based methods which are much more difficult to hide and to make privacy-friendly. Multi-party computation is difficultly compatible with rule-based methods. Fuzzy logic \cite{Shanmugavadivu2011NetworkLogic,Rout2015ADetection} is also used but much less common. Another technique is naive Bayes \cite{Chebrolu2005FeatureSystems}, but tends to have a lesser accuracy, and hidden Markov models \cite{Chen2016AnomalyModel,Tsai2007DetectingModels} that suffer from the same problem. The last two and most used methods are support vector machines and nearest neighbours methods. A lot of less classical methods have also been tested, but little research has been focused on them \cite{Sabhnani2003ApplicationContext}.

Mukkamala et al. have successfully used support vector machines to make the distinction between normal and attack classes using a simple SVM with Gaussian kernels~\cite{Mukkamala2002IntrusionMachines}. Much more complex models have also been used combining KPCA and SVM and training the parameters with genetic algorithms \cite{Kuang2014ADetection}. Ming et al. have showed that adding data-points to the data-set based on aggregation of that same data-base allows to discover more complicated attacks with support vector machines~\cite{MingTian2004UsingAttacks}. This same idea has also been successfully implemented using random forests classifiers~\cite{Akashdeep2017AClassifier}.  Investigations have also been conducted on how to reduce the training set size of SVMs for intrusion detection systems training~\cite{Khan2007AClustering,Al-Yaseen2017Multi-levelSystem}. In general SVMs are able to detect almost all kinds of problems if the model it is used in is well built. This shows the importance of the research around support vector machines for intrusion detection systems. 

Due to the cost of multi-party computation, the data-set sizes used during the secure computation of the algorithm have to be reduced as much as possible without losing accuracy. The feature-size reduction has been implemented using principal component analysis decomposition and $\chi^2$ feature selection~\cite{Eid2010PrincipleSystem,Ikram2016ImprovingSVM,SumaiyaThaseen2017IntrusionSVM,Yang:1997:CSF:645526.657137}. In general, it seems that SVM are almost always using Gaussian kernel functions, sometimes polynomial, but never linear.

The nearest neighbours algorithm has also been studied for feature reduction with PCA and KPCA~\cite{Elkhadir2016IntrusionMethods}. However, algorithms for reducing the data-points number like the one proposed in \cite{Angiulli2005FastRule} seem to never have been tested.







