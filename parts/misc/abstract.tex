\clearpage

\selectlanguage{english}
\begin{abstract}
In this thesis, we present a set of practically usable machine-learning algorithms for intrusion detection systems using multi-party computation (secret sharing). This allows a user to query an already trained model preserving both the privacy of the query and of the model. We investigate two major classes of machine-learning algorithms broadly used on anomaly-based intrusion detection systems: support vector machines, both linear and non-linear, and nearest neighbors classifiers. In addition, different data-reduction methods in the feature space are investigated such as the principal components analysis decomposition or the chi-square feature selection. Instance space reduction methods are also investigated such as the condensed nearest neighbors algorithm, which has been applied for the first time to intrusion detection systems, or the k-means clustering. We also systematically compare two different multi-class models for support vector machines.

Based on these algorithms, we investigate how they can be made privacy-friendly. Different methods to achieve the privacy-friendliness are briefly described such as differential privacy, fully homomorphic encryption, garbled circuits and secret sharing. We justify our choice for the secret sharing and explain how we can use it to achieve a privacy-friendly evaluation on the classifiers. Finally, we benchmark the results of the privacy-friendly algorithms and their variants using data reduction. 

Linear support vector machines allow a rapid evaluation for a good accuracy. The best performance is achieved using the chi-square reduction. Higher accuracies can be achieved with non-linear support vector machines and nearest neighbors. However, compared to nearest neighbors, non-linear support vector machines are much more expensive using multi-party computation due to the need for dual evaluation. Nearest neighbors are also very expensive, but can be reduced to practically feasible evaluation times using the condensed nearest neighbors beforehand. This way we exploit the trade-off between expensive clear pre-processing and a lightweight secret model. When applying feature size reduction to the nearest neighbors, the PCA reduction seems more adapted than the chi-square feature selection.
\end{abstract}

\selectlanguage{dutch} 
\begin{abstract}
In dit masterproef presenteren we een set van praktisch bruikbare algoritmes voor inbraakdetectiesystemen die gebruik maken van multi-party computation (secret sharing). Dit laat een gebruiker toe om een reeds getraind model te bevragen met behoud van zowel de privacy van de query als de modelparameters. We onderzoeken twee belangrijke klassen van machine-learning algoritmes die op grote schaal worden gebruikt op anomaliegebaseerde inbraakdetectiesystemen: support vector machines classificatoren, zowel lineaire als niet-lineaire, en naaste buren classificatoren. Daarnaast worden verschillende datareductiemethoden in de feature dimensie onderzocht, zoals de principal component analysis decompositie of de chi-kwadraatselectie. Reductiemethoden in de instance set worden ook onderzocht, zoals het gecondenseerde naaste buren, dat voor het eerst wordt toegepast op inbraakdetectiesystemen, of de k-means clusteringmethode. We vergelijken ook systematisch twee verschillende multi-class modellen voor ondersteunende vectormachines.

Op basis van deze algoritmes, onderzoeken we hoe ze privacyvriendelijk kunnen worden gemaakt. Verschillende methodes om de privacy-vriendelijkheid te bereiken worden kort beschreven zoals differentiÃ«le privacy, fully homomorphic encryptie, garbled circuits en secret sharing. We rechtvaardigen onze keuze voor het gebruik van secret sharing en leggen uit hoe we deze om tot een privacyvriendelijke evaluatie van de classifiers te komen. Tot slot benchmarken we de resultaten van de privacyvriendelijke algoritmes en hun varianten die gebruik maken van datareductie. 

Lineaire support vector machines maken een snelle evaluatie mogelijk voor een goede nauwkeurigheid. De beste resultaten worden bereikt met de chi-kwadraatselectie. Hogere nauwkeurigheid kan worden bereikt met niet-lineaire support vector machines en de naaste buren. In vergelijking met de naaste buren zijn niet-lineaire support vector machines veel duurder met multi-party computation omwille van de nood voor een duale evaluatie. Naaste buren zijn ook duur, maar kunnen worden gereduceerd tot praktisch haalbare evaluatietijden met behulp van de gecondenseerde naaste buren. Op deze manier maken we gebruik van de trade-off tussen dure clear pre-processing en een licht geheim model. Bij de toepassing van de feature reductie bij de naaste buren lijkt de PCA-reductie meer aangepast dan de chi-kwadraatfunctieselectie.
\end{abstract}

\selectlanguage{english}